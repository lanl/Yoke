studyIDX,KNODES,NGPUS,NUM_WORKERS,BATCH_SIZE,NTRN_BATCH,NVAL_BATCH,ANCHOR_LR,NUM_CYCLES,MIN_FRACTION,TERMINAL_STEPS,WARMUP_STEPS,train_script
# batch_size=16 causes CUDA OOM error
# batch_size=8 with 100 batches per epoch yields ~4min epochs
#
# batch_size=8 with 1500 batches per epoch, ~60min epochs.
# 500 batches per validation, ~20min val-epoch.
1,1,4,1,8,80,24,2.0e-3,0.5,0.5,800,400,train_lsc_policy.py

